{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eacf9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType,DoubleType,TimestampType\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bd8e103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/29 15:06:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('module_05_homework') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9781571d",
   "metadata": {},
   "source": [
    "#### Question 1: Execute spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba96c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2158eb",
   "metadata": {},
   "source": [
    "##### Answer 01: '3.3.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8390c9",
   "metadata": {},
   "source": [
    "### Question 2: What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39a68640",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the the csv file into pandas dataframe to get schema\n",
    "\n",
    "fhv_10_df = pd.read_csv('/home/abdol/data_zoomcamp/05-batch/data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2781d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num       object\n",
       "pickup_datetime            object\n",
       "dropOff_datetime           object\n",
       "PUlocationID              float64\n",
       "DOlocationID              float64\n",
       "SR_Flag                   float64\n",
       "Affiliated_base_number     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhv_10_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6776eebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2019-10-01 00:23:00</td>\n",
       "      <td>2019-10-01 00:35:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2019-10-01 00:11:29</td>\n",
       "      <td>2019-10-01 00:13:22</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:11:43</td>\n",
       "      <td>2019-10-01 00:37:20</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:56:29</td>\n",
       "      <td>2019-10-01 00:57:47</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:23:09</td>\n",
       "      <td>2019-10-01 00:28:27</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num      pickup_datetime     dropOff_datetime  \\\n",
       "0               B00009  2019-10-01 00:23:00  2019-10-01 00:35:00   \n",
       "1               B00013  2019-10-01 00:11:29  2019-10-01 00:13:22   \n",
       "2               B00014  2019-10-01 00:11:43  2019-10-01 00:37:20   \n",
       "3               B00014  2019-10-01 00:56:29  2019-10-01 00:57:47   \n",
       "4               B00014  2019-10-01 00:23:09  2019-10-01 00:28:27   \n",
       "\n",
       "   PUlocationID  DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0         264.0         264.0      NaN                 B00009  \n",
       "1         264.0         264.0      NaN                 B00013  \n",
       "2         264.0         264.0      NaN                 B00014  \n",
       "3         264.0         264.0      NaN                 B00014  \n",
       "4         264.0         264.0      NaN                 B00014  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhv_10_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06b53a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    \n",
    "    StructField('dispatching_base_num',StringType(),True),\n",
    "    StructField('pickup_datetime',TimestampType(),True),\n",
    "    StructField('dropOff_datetime',TimestampType(),True),\n",
    "    StructField('PUlocationID',IntegerType(),True),\n",
    "    StructField('DOlocationID',IntegerType(),True),\n",
    "    StructField('SR_Flag',StringType(),True),\n",
    "    StructField('Affiliated_base_number',StringType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e6a61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhv_10_df = spark.read \\\n",
    "                 .option(\"header\",\"true\") \\\n",
    "                 .schema(schema) \\\n",
    "                 .csv(\"/home/abdol/data_zoomcamp/05-batch/data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cbcc8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fhv_10_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "680b716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhv_10_df = fhv_10_df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56cb6f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fhv_10_df.write.parquet('/home/abdol/data_zoomcamp/05-batch/data/parquet/fhv/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88fff92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 40MB\r\n",
      "-rw-r--r-- 1 abdol abdol 0MB Feb 29 15:18 _SUCCESS\r\n",
      "-rw-r--r-- 1 abdol abdol 7MB Feb 29 15:18 part-00000-7bb16ce4-e57a-45c7-9bee-e08eb293efbf-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 abdol abdol 7MB Feb 29 15:18 part-00001-7bb16ce4-e57a-45c7-9bee-e08eb293efbf-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 abdol abdol 7MB Feb 29 15:18 part-00002-7bb16ce4-e57a-45c7-9bee-e08eb293efbf-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 abdol abdol 7MB Feb 29 15:18 part-00003-7bb16ce4-e57a-45c7-9bee-e08eb293efbf-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 abdol abdol 7MB Feb 29 15:18 part-00004-7bb16ce4-e57a-45c7-9bee-e08eb293efbf-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 abdol abdol 7MB Feb 29 15:18 part-00005-7bb16ce4-e57a-45c7-9bee-e08eb293efbf-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/parquet/fhv/2019/10 -lh --block-size=MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9cadbc",
   "metadata": {},
   "source": [
    "#### Answer 02: Average size = 6 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250325b1",
   "metadata": {},
   "source": [
    "#### Question 03: How many taxi trips were there on the 15th of October?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9968013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdol/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "fhv_10_df.registerTempTable('fhv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6303c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_15_count = spark.sql(\"\"\"\n",
    "                SELECT \n",
    "                        COUNT(*) AS COUNT_TRIPS\n",
    "                FROM \n",
    "                        fhv\n",
    "                WHERE TO_DATE(pickup_datetime) = '2019-10-15'\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dbdc6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|COUNT_TRIPS|\n",
      "+-----------+\n",
      "|      62610|\n",
      "+-----------+\n",
      "\n",
      "COUNT OF TRIPS STARTED AT 15/10 IS None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print('COUNT OF TRIPS STARTED AT 15/10 IS {}'.format(df_trips_15_count.show()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa997967",
   "metadata": {},
   "source": [
    "#### ANSWER 03: 62,610"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa39e17",
   "metadata": {},
   "source": [
    "#### Question 04: What is the length of the longest trip in the dataset in hours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0e485d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_trip_df = spark.sql(\"\"\"\n",
    "                SELECT  \n",
    "                        (unix_timestamp(dropOff_datetime) - unix_timestamp(pickup_datetime)) / 3600 AS hours_difference\n",
    "                FROM fhv\n",
    "                ORDER BY hours_difference DESC \n",
    "                LIMIT 1\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8944a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 51:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|hours_difference|\n",
      "+----------------+\n",
      "|        631152.5|\n",
      "+----------------+\n",
      "\n",
      "LONGEST TRIP IN HOURS None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print('LONGEST TRIP IN HOURS {}'.format(longest_trip_df.show()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba6dc0",
   "metadata": {},
   "source": [
    "#### ANSWER 04: 631,152.50 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8720a89",
   "metadata": {},
   "source": [
    "#### Question 05: Spark’s User Interface which shows the application's dashboard runs on which local port?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e91a88",
   "metadata": {},
   "source": [
    "#### Answer 05: port 4040"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca1eb5",
   "metadata": {},
   "source": [
    "#### Question 06:  Least frequent pickup location zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "221c8271",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone_schema = StructType([\n",
    "            StructField('LocationID',IntegerType(),True),\n",
    "            StructField('Borough',StringType(),True),\n",
    "            StructField('Zone',StringType(),True),\n",
    "            StructField('service_zone',StringType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f00166b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone_lkp_df = spark.read \\\n",
    "                        .option(\"header\",\"true\") \\\n",
    "                        .schema(taxi_zone_schema) \\\n",
    "                        .csv(\"/home/abdol/data_zoomcamp/05-batch/data/lookup/taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01a349f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_zone_lkp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c467ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone_lkp_df.createOrReplaceTempView('zone_lkp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "937d71b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "least_frequent_zone_df = spark.sql(\"\"\"\n",
    "\n",
    "        SELECT \n",
    "                fhv.PUlocationID,\n",
    "                zone_lkp.Zone,\n",
    "                COUNT(*) AS COUNT_TRIPS\n",
    "        FROM \n",
    "            fhv \n",
    "            LEFT JOIN\n",
    "            zone_lkp \n",
    "            ON fhv.PUlocationID = zone_lkp.LocationID\n",
    "        GROUP BY 1,2\n",
    "        ORDER BY COUNT_TRIPS ASC\n",
    "        LIMIT 1\n",
    "             \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0d54b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 78:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       Zone|\n",
      "+-----------+\n",
      "|Jamaica Bay|\n",
      "+-----------+\n",
      "\n",
      "LEAST FREQUENT ZONE IS None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print('LEAST FREQUENT ZONE IS {} '.format(least_frequent_zone_df.select('Zone').show()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b34f197",
   "metadata": {},
   "source": [
    "#### Answer 06: Jamaica Bay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83160cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
